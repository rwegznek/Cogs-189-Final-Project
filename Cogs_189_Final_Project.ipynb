{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X170</th>\n",
       "      <th>X171</th>\n",
       "      <th>X172</th>\n",
       "      <th>X173</th>\n",
       "      <th>X174</th>\n",
       "      <th>X175</th>\n",
       "      <th>X176</th>\n",
       "      <th>X177</th>\n",
       "      <th>X178</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X21.V1.791</td>\n",
       "      <td>135</td>\n",
       "      <td>190</td>\n",
       "      <td>229</td>\n",
       "      <td>223</td>\n",
       "      <td>192</td>\n",
       "      <td>125</td>\n",
       "      <td>55</td>\n",
       "      <td>-9</td>\n",
       "      <td>-33</td>\n",
       "      <td>...</td>\n",
       "      <td>-17</td>\n",
       "      <td>-15</td>\n",
       "      <td>-31</td>\n",
       "      <td>-77</td>\n",
       "      <td>-103</td>\n",
       "      <td>-127</td>\n",
       "      <td>-116</td>\n",
       "      <td>-83</td>\n",
       "      <td>-51</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X15.V1.924</td>\n",
       "      <td>386</td>\n",
       "      <td>382</td>\n",
       "      <td>356</td>\n",
       "      <td>331</td>\n",
       "      <td>320</td>\n",
       "      <td>315</td>\n",
       "      <td>307</td>\n",
       "      <td>272</td>\n",
       "      <td>244</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>150</td>\n",
       "      <td>146</td>\n",
       "      <td>152</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>154</td>\n",
       "      <td>143</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X8.V1.1</td>\n",
       "      <td>-32</td>\n",
       "      <td>-39</td>\n",
       "      <td>-47</td>\n",
       "      <td>-37</td>\n",
       "      <td>-32</td>\n",
       "      <td>-36</td>\n",
       "      <td>-57</td>\n",
       "      <td>-73</td>\n",
       "      <td>-85</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>-12</td>\n",
       "      <td>-30</td>\n",
       "      <td>-35</td>\n",
       "      <td>-35</td>\n",
       "      <td>-36</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X16.V1.60</td>\n",
       "      <td>-105</td>\n",
       "      <td>-101</td>\n",
       "      <td>-96</td>\n",
       "      <td>-92</td>\n",
       "      <td>-89</td>\n",
       "      <td>-95</td>\n",
       "      <td>-102</td>\n",
       "      <td>-100</td>\n",
       "      <td>-87</td>\n",
       "      <td>...</td>\n",
       "      <td>-82</td>\n",
       "      <td>-81</td>\n",
       "      <td>-80</td>\n",
       "      <td>-77</td>\n",
       "      <td>-85</td>\n",
       "      <td>-77</td>\n",
       "      <td>-72</td>\n",
       "      <td>-69</td>\n",
       "      <td>-65</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X20.V1.54</td>\n",
       "      <td>-9</td>\n",
       "      <td>-65</td>\n",
       "      <td>-98</td>\n",
       "      <td>-102</td>\n",
       "      <td>-78</td>\n",
       "      <td>-48</td>\n",
       "      <td>-16</td>\n",
       "      <td>0</td>\n",
       "      <td>-21</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-12</td>\n",
       "      <td>-32</td>\n",
       "      <td>-41</td>\n",
       "      <td>-65</td>\n",
       "      <td>-83</td>\n",
       "      <td>-89</td>\n",
       "      <td>-73</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed   X1   X2   X3   X4   X5   X6   X7   X8   X9  ...  X170  X171  \\\n",
       "0  X21.V1.791  135  190  229  223  192  125   55   -9  -33  ...   -17   -15   \n",
       "1  X15.V1.924  386  382  356  331  320  315  307  272  244  ...   164   150   \n",
       "2     X8.V1.1  -32  -39  -47  -37  -32  -36  -57  -73  -85  ...    57    64   \n",
       "3   X16.V1.60 -105 -101  -96  -92  -89  -95 -102 -100  -87  ...   -82   -81   \n",
       "4   X20.V1.54   -9  -65  -98 -102  -78  -48  -16    0  -21  ...     4     2   \n",
       "\n",
       "   X172  X173  X174  X175  X176  X177  X178  y  \n",
       "0   -31   -77  -103  -127  -116   -83   -51  4  \n",
       "1   146   152   157   156   154   143   129  1  \n",
       "2    48    19   -12   -30   -35   -35   -36  5  \n",
       "3   -80   -77   -85   -77   -72   -69   -65  5  \n",
       "4   -12   -32   -41   -65   -83   -89   -73  5  \n",
       "\n",
       "[5 rows x 180 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Epileptic Seizure Recognition.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df.iterrows():\n",
    "    value = 0\n",
    "    if row['y'] == 1:\n",
    "        value = 1\n",
    "    df.at[i, 'y'] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfy = df.groupby(\"y\")\n",
    "df1 = dfy.get_group(1)\n",
    "df0 = dfy.get_group(0)\n",
    "X1 = df1.iloc[:,1:179].values\n",
    "X0 = df0.iloc[:,1:179].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg1 = X1.mean(axis = 0)\n",
    "avg0 = X0.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a3b33b3c8>,\n",
       " <matplotlib.lines.Line2D at 0x1a3c867470>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "black = mpatches.Patch(color='k', label = 'class0')\n",
    "magenta = mpatches.Patch(color='m', label = 'class1')\n",
    "plt.figure(figsize = (10, 5))\n",
    "plt.legend(handles = [black, magenta])\n",
    "plt.plot(avg1, 'm', avg0, 'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate Labels from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,1:179].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.iloc[:,179].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Into Train/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': ['scale', 0.001, 0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "C = [0.001, .01, .1, 1, 10]\n",
    "gamma = ['scale', .001, .01, .1, 1]\n",
    "params = {'C': C, 'gamma': gamma}\n",
    "svm = GridSearchCV(svm, params, cv = 3)\n",
    "svm.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'C': 10, 'gamma': 'scale'}\n",
      "training accuracy:  99.80434782608695\n",
      "testing accuracy:  97.78260869565217\n"
     ]
    }
   ],
   "source": [
    "print('best parameters: ', svm.best_params_)\n",
    "C_val = svm.best_params_.get('C')\n",
    "gamma_val = svm.best_params_.get('gamma')\n",
    "svm = SVC(C = C_val, gamma = gamma_val)\n",
    "svm.fit(X_train, Y_train)\n",
    "acc_svm_train = svm.score(X_train, Y_train) * 100\n",
    "print('training accuracy: ', acc_svm_train)\n",
    "acc_svm = svm.score(X_test, Y_test) * 100\n",
    "print('testing accuracy: ', acc_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_svm = LinearSVC()\n",
    "C = [0.001, .01, .1, 1, 10]\n",
    "params = {'C': C}\n",
    "linear_svm = GridSearchCV(linear_svm, params, cv = 3)\n",
    "linear_svm.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'C': 0.001}\n",
      "training accuracy:  83.77173913043478\n",
      "testing accuracy:  85.04347826086956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "print('best parameters: ', linear_svm.best_params_)\n",
    "C_val = linear_svm.best_params_.get('C')\n",
    "linear_svm = LinearSVC(C = C_val)\n",
    "linear_svm.fit(X_train, Y_train)\n",
    "acc_linear_svm_train = linear_svm.score(X_train, Y_train) * 100\n",
    "print('training accuracy: ', acc_linear_svm_train)\n",
    "acc_linear_svm = linear_svm.score(X_test, Y_test) * 100\n",
    "print('testing accuracy: ', acc_linear_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "k_vals = {'n_neighbors': np.arange(1, 15)}\n",
    "knn = GridSearchCV(knn, k_vals, cv = 3)\n",
    "knn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'n_neighbors': 1}\n",
      "training accuracy:  100.0\n",
      "testing accuracy:  95.26086956521739\n"
     ]
    }
   ],
   "source": [
    "print('best parameters: ', knn.best_params_)\n",
    "neighbs = knn.best_params_.get('n_neighbors')\n",
    "knn = KNeighborsClassifier(n_neighbors = neighbs)\n",
    "knn.fit(X_train, Y_train)\n",
    "acc_knn_train = knn.score(X_train, Y_train) * 100\n",
    "print('training accuracy: ', acc_knn_train)\n",
    "acc_knn = knn.score(X_test, Y_test) * 100\n",
    "print('testing accuracy: ', acc_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_depth': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]), 'criterion': ['entropy', 'gini']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "params = {'max_depth': np.arange(1, 15), 'criterion': ['entropy', 'gini']}\n",
    "dt = GridSearchCV(dt, params, cv = 3)\n",
    "dt.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'criterion': 'entropy', 'max_depth': 13}\n",
      "training accuracy:  98.98913043478261\n",
      "testing accuracy:  94.47826086956522\n"
     ]
    }
   ],
   "source": [
    "print('best parameters: ', dt.best_params_)\n",
    "depth = dt.best_params_.get('max_depth') \n",
    "cr = dt.best_params_.get('criterion')\n",
    "dt = DecisionTreeClassifier(max_depth = depth, criterion = cr)\n",
    "dt.fit(X_train, Y_train)\n",
    "acc_dt_train = dt.score(X_train, Y_train) * 100\n",
    "print('training accuracy: ', acc_dt_train)\n",
    "acc_dt = dt.score(X_test, Y_test) * 100\n",
    "print('testing accuracy: ', acc_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'solver': ['svd', 'lsqr', 'eigen']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "params = {'solver': ['svd', 'lsqr', 'eigen']}\n",
    "lda = GridSearchCV(lda, params, cv = 3)\n",
    "lda.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'solver': 'svd'}\n",
      "training accuracy:  83.04347826086956\n",
      "testing accuracy:  82.86956521739131\n"
     ]
    }
   ],
   "source": [
    "print('best parameters: ', lda.best_params_)\n",
    "sol = lda.best_params_.get('solver')\n",
    "lda = LinearDiscriminantAnalysis(solver = sol)\n",
    "lda.fit(X_train, Y_train)\n",
    "acc_lda_train = lda.score(X_train, Y_train) * 100\n",
    "print('training accuracy: ', acc_lda_train)\n",
    "acc_lda = lda.score(X_test, Y_test) * 100\n",
    "print('testing accuracy: ', acc_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_features': ['sqrt', 'log2'], 'criterion': ['gini', 'entropy']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramfeat = {'max_features':['sqrt', 'log2'], 'criterion': ['gini', 'entropy']}\n",
    "rf = RandomForestClassifier(n_estimators=1024)\n",
    "rf = GridSearchCV(rf, paramfeat, cv=3)\n",
    "rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'criterion': 'gini', 'max_features': 'sqrt'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  99.90217391304348\n",
      "testing accuracy:  97.30434782608695\n"
     ]
    }
   ],
   "source": [
    "print('best parameters: ', rf.best_params_)\n",
    "feats = rf.best_params_.get('max_features') \n",
    "cr = rf.best_params_.get('criterion')\n",
    "rf = RandomForestClassifier(max_features = feats, criterion = cr)\n",
    "rf.fit(X_train, Y_train)\n",
    "acc_rf_train = rf.score(X_train, Y_train) * 100\n",
    "print('training accuracy: ', acc_rf_train)\n",
    "acc_rf = rf.score(X_test, Y_test) * 100\n",
    "print('testing accuracy: ', acc_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0312 11:08:23.715127 4508984768 deprecation_wrapper.py:119] From /Applications/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=178, units=80, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "W0312 11:08:23.732647 4508984768 deprecation_wrapper.py:119] From /Applications/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0312 11:08:23.734588 4508984768 deprecation_wrapper.py:119] From /Applications/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=80, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "W0312 11:08:23.767445 4508984768 deprecation_wrapper.py:119] From /Applications/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0312 11:08:23.782228 4508984768 deprecation_wrapper.py:119] From /Applications/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0312 11:08:23.785655 4508984768 deprecation.py:323] From /Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n",
      "W0312 11:08:23.976900 4508984768 deprecation_wrapper.py:119] From /Applications/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9200/9200 [==============================] - 1s 91us/step - loss: 0.4393 - acc: 0.8501\n",
      "Epoch 2/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.2837 - acc: 0.9401: 0s - loss: 0.3091 - acc: 0 - ETA: 0s - loss: 0.2872 - acc: 0.94\n",
      "Epoch 3/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.2234 - acc: 0.9523\n",
      "Epoch 4/100\n",
      "9200/9200 [==============================] - 1s 64us/step - loss: 0.1796 - acc: 0.9592\n",
      "Epoch 5/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.1454 - acc: 0.9637\n",
      "Epoch 6/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.1213 - acc: 0.9690\n",
      "Epoch 7/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.1229 - acc: 0.9672\n",
      "Epoch 8/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0976 - acc: 0.9764\n",
      "Epoch 9/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0827 - acc: 0.9798\n",
      "Epoch 10/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0960 - acc: 0.9739\n",
      "Epoch 11/100\n",
      "9200/9200 [==============================] - 1s 70us/step - loss: 0.0731 - acc: 0.9811: 0s - loss: 0.0756 - acc: 0.98\n",
      "Epoch 12/100\n",
      "9200/9200 [==============================] - 1s 67us/step - loss: 0.0722 - acc: 0.9808\n",
      "Epoch 13/100\n",
      "9200/9200 [==============================] - 1s 63us/step - loss: 0.0656 - acc: 0.9815\n",
      "Epoch 14/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0598 - acc: 0.9810\n",
      "Epoch 15/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0544 - acc: 0.9861\n",
      "Epoch 16/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0468 - acc: 0.9885\n",
      "Epoch 17/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0503 - acc: 0.9843\n",
      "Epoch 18/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0496 - acc: 0.9861\n",
      "Epoch 19/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0596 - acc: 0.9840\n",
      "Epoch 20/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0392 - acc: 0.9900\n",
      "Epoch 21/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0351 - acc: 0.9905\n",
      "Epoch 22/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0387 - acc: 0.9902: 0s - loss: 0.0326 - acc: 0\n",
      "Epoch 23/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0393 - acc: 0.9872\n",
      "Epoch 24/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0464 - acc: 0.9883\n",
      "Epoch 25/100\n",
      "9200/9200 [==============================] - 1s 65us/step - loss: 0.0302 - acc: 0.9928\n",
      "Epoch 26/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 27/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0297 - acc: 0.9920\n",
      "Epoch 28/100\n",
      "9200/9200 [==============================] - 1s 67us/step - loss: 0.0301 - acc: 0.9918\n",
      "Epoch 29/100\n",
      "9200/9200 [==============================] - 1s 63us/step - loss: 0.0363 - acc: 0.9891\n",
      "Epoch 30/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0248 - acc: 0.9926: 0s - loss: 0.0238 - acc: 0.99\n",
      "Epoch 31/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0258 - acc: 0.9933\n",
      "Epoch 32/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0323 - acc: 0.9904\n",
      "Epoch 33/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0319 - acc: 0.9912\n",
      "Epoch 34/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0290 - acc: 0.9915\n",
      "Epoch 35/100\n",
      "9200/9200 [==============================] - 1s 67us/step - loss: 0.0264 - acc: 0.9927\n",
      "Epoch 36/100\n",
      "9200/9200 [==============================] - 1s 67us/step - loss: 0.0217 - acc: 0.9933\n",
      "Epoch 37/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0311 - acc: 0.9914\n",
      "Epoch 38/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0251 - acc: 0.9929\n",
      "Epoch 39/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0171 - acc: 0.9953: 0s - loss: 0.0173 - acc: 0.995\n",
      "Epoch 40/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0171 - acc: 0.9955\n",
      "Epoch 41/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0210 - acc: 0.9947: 0s - loss: 0.0146 - acc\n",
      "Epoch 42/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0423 - acc: 0.9877\n",
      "Epoch 43/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0243 - acc: 0.9928TA: 0s - loss: 0.0254 - ac\n",
      "Epoch 44/100\n",
      "9200/9200 [==============================] - 1s 67us/step - loss: 0.0177 - acc: 0.9946\n",
      "Epoch 45/100\n",
      "9200/9200 [==============================] - 1s 67us/step - loss: 0.0221 - acc: 0.9938: 0s - loss: 0.0232 - acc: 0\n",
      "Epoch 46/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0171 - acc: 0.9952\n",
      "Epoch 47/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0272 - acc: 0.9926\n",
      "Epoch 48/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0247 - acc: 0.9926\n",
      "Epoch 49/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0221 - acc: 0.9932\n",
      "Epoch 50/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0248 - acc: 0.9932: 0s - loss: 0.0233 - acc: 0.993\n",
      "Epoch 51/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0240 - acc: 0.9925: 0s - loss: 0.0232 - acc: 0.992\n",
      "Epoch 52/100\n",
      "9200/9200 [==============================] - 1s 66us/step - loss: 0.0254 - acc: 0.9942\n",
      "Epoch 53/100\n",
      "9200/9200 [==============================] - 1s 65us/step - loss: 0.0215 - acc: 0.9947\n",
      "Epoch 54/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0389 - acc: 0.9888\n",
      "Epoch 55/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0450 - acc: 0.9920\n",
      "Epoch 56/100\n",
      "9200/9200 [==============================] - 1s 67us/step - loss: 0.0152 - acc: 0.9964: 0s - loss: 0.0168 - acc: \n",
      "Epoch 57/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0102 - acc: 0.9972: 0s - loss: 0.0094 - acc: \n",
      "Epoch 58/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0280 - acc: 0.9917\n",
      "Epoch 59/100\n",
      "9200/9200 [==============================] - 1s 70us/step - loss: 0.0254 - acc: 0.9945\n",
      "Epoch 60/100\n",
      "9200/9200 [==============================] - 1s 67us/step - loss: 0.0114 - acc: 0.9975\n",
      "Epoch 61/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0209 - acc: 0.9945\n",
      "Epoch 62/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0217 - acc: 0.9948\n",
      "Epoch 63/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0205 - acc: 0.9951: 0s - loss: 0.0123 - acc: \n",
      "Epoch 64/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0188 - acc: 0.9939\n",
      "Epoch 65/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0139 - acc: 0.9970: 0s - loss: 0.0142 - acc: 0.997\n",
      "Epoch 66/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0163 - acc: 0.9960: 0s - loss: 0.0136 - acc: 0.9\n",
      "Epoch 67/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0220 - acc: 0.9930\n",
      "Epoch 68/100\n",
      "9200/9200 [==============================] - 1s 66us/step - loss: 0.0368 - acc: 0.9909\n",
      "Epoch 69/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0168 - acc: 0.9957\n",
      "Epoch 70/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0098 - acc: 0.9985\n",
      "Epoch 71/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0158 - acc: 0.9955\n",
      "Epoch 72/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0220 - acc: 0.9948\n",
      "Epoch 73/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0215 - acc: 0.9939\n",
      "Epoch 74/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0106 - acc: 0.9971\n",
      "Epoch 75/100\n",
      "9200/9200 [==============================] - 1s 65us/step - loss: 0.0187 - acc: 0.9954\n",
      "Epoch 76/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0180 - acc: 0.9952: 0s - loss: 0.0160 - acc: 0. - ETA: 0s - loss: 0.0185 - acc: 0.995\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0133 - acc: 0.9966\n",
      "Epoch 78/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0245 - acc: 0.9935\n",
      "Epoch 79/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0163 - acc: 0.9957\n",
      "Epoch 80/100\n",
      "9200/9200 [==============================] - 1s 67us/step - loss: 0.0175 - acc: 0.9947\n",
      "Epoch 81/100\n",
      "9200/9200 [==============================] - 1s 63us/step - loss: 0.0152 - acc: 0.9966\n",
      "Epoch 82/100\n",
      "9200/9200 [==============================] - ETA: 0s - loss: 0.0163 - acc: 0.995 - 1s 66us/step - loss: 0.0155 - acc: 0.9955\n",
      "Epoch 83/100\n",
      "9200/9200 [==============================] - 1s 65us/step - loss: 0.0196 - acc: 0.9939\n",
      "Epoch 84/100\n",
      "9200/9200 [==============================] - 1s 67us/step - loss: 0.0097 - acc: 0.9978\n",
      "Epoch 85/100\n",
      "9200/9200 [==============================] - 1s 63us/step - loss: 0.0252 - acc: 0.9932\n",
      "Epoch 86/100\n",
      "9200/9200 [==============================] - 1s 67us/step - loss: 0.0222 - acc: 0.9932\n",
      "Epoch 87/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0080 - acc: 0.9984\n",
      "Epoch 88/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0048 - acc: 0.9996\n",
      "Epoch 89/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0139 - acc: 0.9966\n",
      "Epoch 90/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0193 - acc: 0.9948\n",
      "Epoch 91/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0095 - acc: 0.9971\n",
      "Epoch 92/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0134 - acc: 0.9965: 0s - loss: 0.0128 - acc: 0\n",
      "Epoch 93/100\n",
      "9200/9200 [==============================] - 1s 67us/step - loss: 0.0239 - acc: 0.9937\n",
      "Epoch 94/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0170 - acc: 0.9959\n",
      "Epoch 95/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0178 - acc: 0.9960\n",
      "Epoch 96/100\n",
      "9200/9200 [==============================] - 1s 66us/step - loss: 0.0149 - acc: 0.9959\n",
      "Epoch 97/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0067 - acc: 0.9988\n",
      "Epoch 98/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0057 - acc: 0.9990\n",
      "Epoch 99/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0236 - acc: 0.9934\n",
      "Epoch 100/100\n",
      "9200/9200 [==============================] - 1s 70us/step - loss: 0.0123 - acc: 0.9965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3e1002e8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann1 = Sequential()\n",
    "ann1.add(Dense(output_dim = 80, init = 'uniform', activation = 'relu', input_dim = 178))\n",
    "ann1.add(Dense(output_dim = 80, init = 'uniform', activation = 'relu'))\n",
    "ann1.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "ann1.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "ann1.fit(X_train, Y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy:  95.43478260869566\n"
     ]
    }
   ],
   "source": [
    "Y_pred1 = ann1.predict(X_test)\n",
    "Y_pred1[Y_pred1 > 0.5] = 1\n",
    "Y_pred1[Y_pred1 <= 0.5] = 0\n",
    "acc_ann1 = accuracy_score(Y_test, Y_pred1) * 100\n",
    "print('testing accuracy: ', acc_ann1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=178, units=80, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=80, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9200/9200 [==============================] - 1s 79us/step - loss: 0.2015 - acc: 0.7987\n",
      "Epoch 2/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 3/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 4/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 5/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 6/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 7/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 8/100\n",
      "9200/9200 [==============================] - 1s 61us/step - loss: 0.2011 - acc: 0.7988\n",
      "Epoch 9/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 10/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 11/100\n",
      "9200/9200 [==============================] - 1s 63us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 12/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 13/100\n",
      "9200/9200 [==============================] - 1s 62us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 14/100\n",
      "9200/9200 [==============================] - 1s 62us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 15/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 16/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 17/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 18/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 19/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 20/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 21/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 22/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 23/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 24/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 25/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 26/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 27/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 28/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 29/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 30/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 31/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 32/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 33/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 34/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2012 - acc: 0.7988: 0s - loss: 0.2003 - acc: 0.799\n",
      "Epoch 35/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 36/100\n",
      "9200/9200 [==============================] - 1s 64us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 37/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 38/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 39/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 40/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 41/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 42/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 43/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 44/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 45/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 46/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 47/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 48/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 49/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 50/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 51/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 52/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 53/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 54/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 55/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 56/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 57/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 58/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 59/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 60/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 61/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 62/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 63/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 64/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 65/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 66/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 67/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 68/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 69/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 70/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 71/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 72/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 73/100\n",
      "9200/9200 [==============================] - 1s 61us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 74/100\n",
      "9200/9200 [==============================] - 1s 61us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 75/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 76/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 77/100\n",
      "9200/9200 [==============================] - 1s 61us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 78/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 79/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 80/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 81/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 83/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 84/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 85/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 86/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 87/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 88/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 89/100\n",
      "9200/9200 [==============================] - 1s 56us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 90/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 91/100\n",
      "9200/9200 [==============================] - 1s 56us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 92/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 93/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 94/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 95/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 96/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 97/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 98/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 99/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 100/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2012 - acc: 0.7988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3dee8898>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann2 = Sequential()\n",
    "ann2.add(Dense(output_dim = 80, init = 'uniform', activation = 'relu', input_dim = 178))\n",
    "ann2.add(Dense(output_dim = 80, init = 'uniform', activation = 'relu'))\n",
    "ann2.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "ann2.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "ann2.fit(X_train, Y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy:  80.47826086956522\n"
     ]
    }
   ],
   "source": [
    "Y_pred2 = ann2.predict(X_test)\n",
    "Y_pred2[Y_pred2 > 0.5] = 1\n",
    "Y_pred2[Y_pred2 <= 0.5] = 0\n",
    "acc_ann2 = accuracy_score(Y_test, Y_pred2) * 100\n",
    "print('testing accuracy: ', acc_ann2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=178, units=80, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=80, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9200/9200 [==============================] - 1s 64us/step - loss: 0.2027 - acc: 0.7978\n",
      "Epoch 2/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2013 - acc: 0.7988\n",
      "Epoch 3/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2013 - acc: 0.7988\n",
      "Epoch 4/100\n",
      "9200/9200 [==============================] - 0s 47us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 5/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 6/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 7/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 8/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 9/100\n",
      "9200/9200 [==============================] - 0s 47us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 10/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 11/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 12/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 13/100\n",
      "9200/9200 [==============================] - 0s 50us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 14/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 15/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 16/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 17/100\n",
      "9200/9200 [==============================] - 0s 47us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 18/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 19/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 20/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 21/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 22/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 23/100\n",
      "9200/9200 [==============================] - 0s 52us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 24/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 25/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 26/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 27/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 28/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 29/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 30/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 31/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 32/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 33/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 34/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 35/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 36/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 37/100\n",
      "9200/9200 [==============================] - 0s 47us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 38/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 39/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988: 0s - loss: 0.2017 - acc: 0.798\n",
      "Epoch 40/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 41/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 42/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 43/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 44/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 45/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 46/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 47/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 48/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 49/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 50/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 51/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 52/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 53/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 54/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 55/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 56/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 57/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 58/100\n",
      "9200/9200 [==============================] - 0s 51us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 59/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 60/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 61/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 62/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 63/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 64/100\n",
      "9200/9200 [==============================] - 0s 47us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 65/100\n",
      "9200/9200 [==============================] - 0s 47us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 66/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 67/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 68/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 69/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 70/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 71/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 72/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 73/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 74/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 75/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 76/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 77/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 78/100\n",
      "9200/9200 [==============================] - 0s 47us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 79/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 80/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 81/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 83/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 84/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 85/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 86/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 87/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 88/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 89/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 90/100\n",
      "9200/9200 [==============================] - 0s 52us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 91/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 92/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 93/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 94/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 95/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 96/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 97/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 98/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 99/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n",
      "Epoch 100/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2012 - acc: 0.7988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a407448d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann3 = Sequential()\n",
    "ann3.add(Dense(output_dim = 80, init = 'uniform', activation = 'relu', input_dim = 178))\n",
    "ann3.add(Dense(output_dim = 80, init = 'uniform', activation = 'relu'))\n",
    "ann3.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "ann3.compile(optimizer = 'SGD', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "ann3.fit(X_train, Y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy:  80.47826086956522\n"
     ]
    }
   ],
   "source": [
    "Y_pred3 = ann3.predict(X_test)\n",
    "Y_pred3[Y_pred3 > 0.5] = 1\n",
    "Y_pred3[Y_pred3 <= 0.5] = 0\n",
    "acc_ann3 = accuracy_score(Y_test, Y_pred3) * 100\n",
    "print('testing accuracy: ', acc_ann3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=178, units=80, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=80, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9200/9200 [==============================] - 1s 80us/step - loss: 0.7326 - acc: 0.8546\n",
      "Epoch 2/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2630 - acc: 0.9297\n",
      "Epoch 3/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2461 - acc: 0.9266: 0s - loss: 0.2406 - acc: 0.\n",
      "Epoch 4/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.4256 - acc: 0.8830\n",
      "Epoch 5/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.3745 - acc: 0.8963\n",
      "Epoch 6/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4231 - acc: 0.8941\n",
      "Epoch 7/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.7057 - acc: 0.8389\n",
      "Epoch 8/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.5234 - acc: 0.8280\n",
      "Epoch 9/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.4961 - acc: 0.8196: 0s - loss: 0.4840 - acc: 0.\n",
      "Epoch 10/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4671 - acc: 0.8326\n",
      "Epoch 11/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.4451 - acc: 0.8307\n",
      "Epoch 12/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4570 - acc: 0.8293\n",
      "Epoch 13/100\n",
      "9200/9200 [==============================] - 1s 56us/step - loss: 0.4726 - acc: 0.8341\n",
      "Epoch 14/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4646 - acc: 0.8248\n",
      "Epoch 15/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.6083 - acc: 0.8163\n",
      "Epoch 16/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.5003 - acc: 0.8150\n",
      "Epoch 17/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4954 - acc: 0.8096\n",
      "Epoch 18/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4842 - acc: 0.8150\n",
      "Epoch 19/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.5128 - acc: 0.8142\n",
      "Epoch 20/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4753 - acc: 0.8171\n",
      "Epoch 21/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.5982 - acc: 0.8088\n",
      "Epoch 22/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.5049 - acc: 0.8101\n",
      "Epoch 23/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4953 - acc: 0.8130\n",
      "Epoch 24/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.5667 - acc: 0.8137\n",
      "Epoch 25/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4837 - acc: 0.8123\n",
      "Epoch 26/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4825 - acc: 0.8168\n",
      "Epoch 27/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.5112 - acc: 0.8176\n",
      "Epoch 28/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.5015 - acc: 0.8095\n",
      "Epoch 29/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4916 - acc: 0.8077: 0s - loss: 0.4956 - acc: 0\n",
      "Epoch 30/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4831 - acc: 0.8136\n",
      "Epoch 31/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4869 - acc: 0.8095\n",
      "Epoch 32/100\n",
      "9200/9200 [==============================] - 1s 56us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 33/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.4917 - acc: 0.8052\n",
      "Epoch 34/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 35/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 36/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.4917 - acc: 0.8052\n",
      "Epoch 37/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4917 - acc: 0.8052\n",
      "Epoch 38/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4918 - acc: 0.8052: 0s - loss: 0.4913 - acc: 0\n",
      "Epoch 39/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 40/100\n",
      "9200/9200 [==============================] - 1s 63us/step - loss: 0.4917 - acc: 0.8052\n",
      "Epoch 41/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4917 - acc: 0.8052\n",
      "Epoch 42/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.4917 - acc: 0.8052\n",
      "Epoch 43/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4918 - acc: 0.8052: 0s - loss: 0.4869 - acc: 0\n",
      "Epoch 44/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 45/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4917 - acc: 0.8052\n",
      "Epoch 46/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4917 - acc: 0.8052\n",
      "Epoch 47/100\n",
      "9200/9200 [==============================] - 1s 61us/step - loss: 0.4918 - acc: 0.8052: 0s - loss: 0.4902 - acc: 0.\n",
      "Epoch 48/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4917 - acc: 0.8052\n",
      "Epoch 49/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 50/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 51/100\n",
      "9200/9200 [==============================] - 1s 62us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 52/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 53/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4917 - acc: 0.8052\n",
      "Epoch 54/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 55/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 56/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 57/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4918 - acc: 0.8052: 0s - loss: 0.4978 - acc: 0.8\n",
      "Epoch 58/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4917 - acc: 0.8052: 0s - loss: 0.4952 - acc: 0.80\n",
      "Epoch 59/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4917 - acc: 0.8052\n",
      "Epoch 60/100\n",
      "9200/9200 [==============================] - 1s 56us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 61/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 62/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 63/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 64/100\n",
      "9200/9200 [==============================] - 1s 56us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 65/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4917 - acc: 0.8052\n",
      "Epoch 66/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 67/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 68/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 69/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 70/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 71/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4917 - acc: 0.8052\n",
      "Epoch 72/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.4917 - acc: 0.8052\n",
      "Epoch 73/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 74/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4917 - acc: 0.8052\n",
      "Epoch 75/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 76/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 77/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4917 - acc: 0.8052\n",
      "Epoch 78/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 79/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4917 - acc: 0.8052\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 81/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.4917 - acc: 0.8052\n",
      "Epoch 82/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4917 - acc: 0.8052\n",
      "Epoch 83/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.4917 - acc: 0.8052\n",
      "Epoch 84/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 85/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 86/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 87/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.4917 - acc: 0.8052\n",
      "Epoch 88/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 89/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 90/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 91/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.4917 - acc: 0.8052\n",
      "Epoch 92/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 93/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 94/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 95/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 96/100\n",
      "9200/9200 [==============================] - 1s 56us/step - loss: 0.4917 - acc: 0.8052\n",
      "Epoch 97/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 98/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.4918 - acc: 0.8052\n",
      "Epoch 99/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4917 - acc: 0.8052: 0s - loss: 0.4940 - acc: 0.80\n",
      "Epoch 100/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.4918 - acc: 0.8052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a42a25e80>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann4 = Sequential()\n",
    "ann4.add(Dense(output_dim = 80, init = 'uniform', activation = 'relu', input_dim = 178))\n",
    "ann4.add(Dense(output_dim = 80, init = 'uniform', activation = 'relu'))\n",
    "ann4.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "ann4.compile(optimizer = 'SGD', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "ann4.fit(X_train, Y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy:  80.91304347826087\n"
     ]
    }
   ],
   "source": [
    "Y_pred4 = ann4.predict(X_test)\n",
    "Y_pred4[Y_pred4 > 0.5] = 1\n",
    "Y_pred4[Y_pred4 <= 0.5] = 0\n",
    "acc_ann4 = accuracy_score(Y_test, Y_pred4) * 100\n",
    "print('testing accuracy: ', acc_ann4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_models = pd.DataFrame({\n",
    "    'Model': ['SVM', 'Linear SVM','KNN', 'Decision Tree', 'LDA', 'Random Forest', 'ANN'],\n",
    "    \n",
    "    'Score': [acc_svm, acc_linear_svm, acc_knn, acc_dt, acc_lda, acc_rf, acc_ann1]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>97.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>97.304348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ANN</td>\n",
       "      <td>95.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>95.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>94.478261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>85.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LDA</td>\n",
       "      <td>82.869565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model      Score\n",
       "0            SVM  97.782609\n",
       "5  Random Forest  97.304348\n",
       "6            ANN  95.434783\n",
       "2            KNN  95.260870\n",
       "3  Decision Tree  94.478261\n",
       "1     Linear SVM  85.043478\n",
       "4            LDA  82.869565"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
