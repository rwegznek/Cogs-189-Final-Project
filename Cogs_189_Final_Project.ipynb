{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X170</th>\n",
       "      <th>X171</th>\n",
       "      <th>X172</th>\n",
       "      <th>X173</th>\n",
       "      <th>X174</th>\n",
       "      <th>X175</th>\n",
       "      <th>X176</th>\n",
       "      <th>X177</th>\n",
       "      <th>X178</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X21.V1.791</td>\n",
       "      <td>135</td>\n",
       "      <td>190</td>\n",
       "      <td>229</td>\n",
       "      <td>223</td>\n",
       "      <td>192</td>\n",
       "      <td>125</td>\n",
       "      <td>55</td>\n",
       "      <td>-9</td>\n",
       "      <td>-33</td>\n",
       "      <td>...</td>\n",
       "      <td>-17</td>\n",
       "      <td>-15</td>\n",
       "      <td>-31</td>\n",
       "      <td>-77</td>\n",
       "      <td>-103</td>\n",
       "      <td>-127</td>\n",
       "      <td>-116</td>\n",
       "      <td>-83</td>\n",
       "      <td>-51</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X15.V1.924</td>\n",
       "      <td>386</td>\n",
       "      <td>382</td>\n",
       "      <td>356</td>\n",
       "      <td>331</td>\n",
       "      <td>320</td>\n",
       "      <td>315</td>\n",
       "      <td>307</td>\n",
       "      <td>272</td>\n",
       "      <td>244</td>\n",
       "      <td>...</td>\n",
       "      <td>164</td>\n",
       "      <td>150</td>\n",
       "      <td>146</td>\n",
       "      <td>152</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>154</td>\n",
       "      <td>143</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X8.V1.1</td>\n",
       "      <td>-32</td>\n",
       "      <td>-39</td>\n",
       "      <td>-47</td>\n",
       "      <td>-37</td>\n",
       "      <td>-32</td>\n",
       "      <td>-36</td>\n",
       "      <td>-57</td>\n",
       "      <td>-73</td>\n",
       "      <td>-85</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>-12</td>\n",
       "      <td>-30</td>\n",
       "      <td>-35</td>\n",
       "      <td>-35</td>\n",
       "      <td>-36</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X16.V1.60</td>\n",
       "      <td>-105</td>\n",
       "      <td>-101</td>\n",
       "      <td>-96</td>\n",
       "      <td>-92</td>\n",
       "      <td>-89</td>\n",
       "      <td>-95</td>\n",
       "      <td>-102</td>\n",
       "      <td>-100</td>\n",
       "      <td>-87</td>\n",
       "      <td>...</td>\n",
       "      <td>-82</td>\n",
       "      <td>-81</td>\n",
       "      <td>-80</td>\n",
       "      <td>-77</td>\n",
       "      <td>-85</td>\n",
       "      <td>-77</td>\n",
       "      <td>-72</td>\n",
       "      <td>-69</td>\n",
       "      <td>-65</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X20.V1.54</td>\n",
       "      <td>-9</td>\n",
       "      <td>-65</td>\n",
       "      <td>-98</td>\n",
       "      <td>-102</td>\n",
       "      <td>-78</td>\n",
       "      <td>-48</td>\n",
       "      <td>-16</td>\n",
       "      <td>0</td>\n",
       "      <td>-21</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-12</td>\n",
       "      <td>-32</td>\n",
       "      <td>-41</td>\n",
       "      <td>-65</td>\n",
       "      <td>-83</td>\n",
       "      <td>-89</td>\n",
       "      <td>-73</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed   X1   X2   X3   X4   X5   X6   X7   X8   X9  ...  X170  X171  \\\n",
       "0  X21.V1.791  135  190  229  223  192  125   55   -9  -33  ...   -17   -15   \n",
       "1  X15.V1.924  386  382  356  331  320  315  307  272  244  ...   164   150   \n",
       "2     X8.V1.1  -32  -39  -47  -37  -32  -36  -57  -73  -85  ...    57    64   \n",
       "3   X16.V1.60 -105 -101  -96  -92  -89  -95 -102 -100  -87  ...   -82   -81   \n",
       "4   X20.V1.54   -9  -65  -98 -102  -78  -48  -16    0  -21  ...     4     2   \n",
       "\n",
       "   X172  X173  X174  X175  X176  X177  X178  y  \n",
       "0   -31   -77  -103  -127  -116   -83   -51  4  \n",
       "1   146   152   157   156   154   143   129  1  \n",
       "2    48    19   -12   -30   -35   -35   -36  5  \n",
       "3   -80   -77   -85   -77   -72   -69   -65  5  \n",
       "4   -12   -32   -41   -65   -83   -89   -73  5  \n",
       "\n",
       "[5 rows x 180 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Epileptic Seizure Recognition.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate Labels from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,1:179].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.iloc[:,179].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Data Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[Y>1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Into Train/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': ['scale', 0.001, 0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "C = [0.001, .01, .1, 1, 10]\n",
    "gamma = ['scale', .001, .01, .1, 1]\n",
    "params = {'C': C, 'gamma': gamma}\n",
    "svm = GridSearchCV(svm, params, cv = 3)\n",
    "svm.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'C': 10, 'gamma': 'scale'}\n",
      "training accuracy:  99.77173913043478\n",
      "testing accuracy:  97.65217391304348\n"
     ]
    }
   ],
   "source": [
    "print('best parameters: ', svm.best_params_)\n",
    "C_val = svm.best_params_.get('C')\n",
    "gamma_val = svm.best_params_.get('gamma')\n",
    "svm = SVC(C = C_val, gamma = gamma_val)\n",
    "svm.fit(X_train, Y_train)\n",
    "acc_svm_train = svm.score(X_train, Y_train) * 100\n",
    "print('training accuracy: ', acc_svm_train)\n",
    "acc_svm = svm.score(X_test, Y_test) * 100\n",
    "print('testing accuracy: ', acc_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_svm = LinearSVC()\n",
    "C = [0.001, .01, .1, 1, 10]\n",
    "params = {'C': C}\n",
    "linear_svm = GridSearchCV(linear_svm, params, cv = 3)\n",
    "linear_svm.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'C': 0.01}\n",
      "training accuracy:  83.41304347826087\n",
      "testing accuracy:  84.04347826086956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "print('best parameters: ', linear_svm.best_params_)\n",
    "C_val = linear_svm.best_params_.get('C')\n",
    "linear_svm = LinearSVC(C = C_val)\n",
    "linear_svm.fit(X_train, Y_train)\n",
    "acc_linear_svm_train = linear_svm.score(X_train, Y_train) * 100\n",
    "print('training accuracy: ', acc_linear_svm_train)\n",
    "acc_linear_svm = linear_svm.score(X_test, Y_test) * 100\n",
    "print('testing accuracy: ', acc_linear_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "k_vals = {'n_neighbors': np.arange(1, 15)}\n",
    "knn = GridSearchCV(knn, k_vals, cv = 3)\n",
    "knn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'n_neighbors': 1}\n",
      "training accuracy:  100.0\n",
      "testing accuracy:  95.08695652173913\n"
     ]
    }
   ],
   "source": [
    "print('best parameters: ', knn.best_params_)\n",
    "neighbs = knn.best_params_.get('n_neighbors')\n",
    "knn = KNeighborsClassifier(n_neighbors = neighbs)\n",
    "knn.fit(X_train, Y_train)\n",
    "acc_knn_train = knn.score(X_train, Y_train) * 100\n",
    "print('training accuracy: ', acc_knn_train)\n",
    "acc_knn = knn.score(X_test, Y_test) * 100\n",
    "print('testing accuracy: ', acc_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_depth': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]), 'criterion': ['entropy', 'gini']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "params = {'max_depth': np.arange(1, 15), 'criterion': ['entropy', 'gini']}\n",
    "dt = GridSearchCV(dt, params, cv = 3)\n",
    "dt.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'criterion': 'entropy', 'max_depth': 12}\n",
      "training accuracy:  98.53260869565217\n",
      "testing accuracy:  94.56521739130434\n"
     ]
    }
   ],
   "source": [
    "print('best parameters: ', dt.best_params_)\n",
    "depth = dt.best_params_.get('max_depth') \n",
    "cr = dt.best_params_.get('criterion')\n",
    "dt = DecisionTreeClassifier(max_depth = depth, criterion = cr)\n",
    "dt.fit(X_train, Y_train)\n",
    "acc_dt_train = dt.score(X_train, Y_train) * 100\n",
    "print('training accuracy: ', acc_dt_train)\n",
    "acc_dt = dt.score(X_test, Y_test) * 100\n",
    "print('testing accuracy: ', acc_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'solver': ['svd', 'lsqr', 'eigen']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "params = {'solver': ['svd', 'lsqr', 'eigen']}\n",
    "lda = GridSearchCV(lda, params, cv = 3)\n",
    "lda.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'solver': 'svd'}\n",
      "training accuracy:  83.27173913043478\n",
      "testing accuracy:  82.56521739130434\n"
     ]
    }
   ],
   "source": [
    "print('best parameters: ', lda.best_params_)\n",
    "sol = lda.best_params_.get('solver')\n",
    "lda = LinearDiscriminantAnalysis(solver = sol)\n",
    "lda.fit(X_train, Y_train)\n",
    "acc_lda_train = lda.score(X_train, Y_train) * 100\n",
    "print('training accuracy: ', acc_lda_train)\n",
    "acc_lda = lda.score(X_test, Y_test) * 100\n",
    "print('testing accuracy: ', acc_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1024, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'max_features': ['sqrt', 'log2'], 'criterion': ['gini', 'entropy']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paramfeat = {'max_features':['sqrt', 'log2'], 'criterion': ['gini', 'entropy']}\n",
    "rf = RandomForestClassifier(n_estimators=1024)\n",
    "rf = GridSearchCV(rf, paramfeat, cv=3)\n",
    "rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'criterion': 'gini', 'max_features': 'sqrt'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:  99.84782608695653\n",
      "testing accuracy:  97.17391304347827\n"
     ]
    }
   ],
   "source": [
    "print('best parameters: ', rf.best_params_)\n",
    "feats = rf.best_params_.get('max_features') \n",
    "cr = rf.best_params_.get('criterion')\n",
    "rf = RandomForestClassifier(max_features = feats, criterion = cr)\n",
    "rf.fit(X_train, Y_train)\n",
    "acc_rf_train = rf.score(X_train, Y_train) * 100\n",
    "print('training accuracy: ', acc_rf_train)\n",
    "acc_rf = rf.score(X_test, Y_test) * 100\n",
    "print('testing accuracy: ', acc_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0312 09:11:06.097717 4696094144 deprecation_wrapper.py:119] From /Applications/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=178, units=80, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "W0312 09:11:06.112787 4696094144 deprecation_wrapper.py:119] From /Applications/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0312 09:11:06.114904 4696094144 deprecation_wrapper.py:119] From /Applications/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=80, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "W0312 09:11:06.153176 4696094144 deprecation_wrapper.py:119] From /Applications/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0312 09:11:06.169711 4696094144 deprecation_wrapper.py:119] From /Applications/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0312 09:11:06.173926 4696094144 deprecation.py:323] From /Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n",
      "W0312 09:11:06.381692 4696094144 deprecation_wrapper.py:119] From /Applications/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9200/9200 [==============================] - 1s 89us/step - loss: 0.4353 - acc: 0.8479\n",
      "Epoch 2/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.2927 - acc: 0.9426\n",
      "Epoch 3/100\n",
      "9200/9200 [==============================] - 1s 70us/step - loss: 0.2194 - acc: 0.9543\n",
      "Epoch 4/100\n",
      "9200/9200 [==============================] - 1s 70us/step - loss: 0.1802 - acc: 0.9586\n",
      "Epoch 5/100\n",
      "9200/9200 [==============================] - 1s 70us/step - loss: 0.1562 - acc: 0.9609\n",
      "Epoch 6/100\n",
      "9200/9200 [==============================] - 1s 71us/step - loss: 0.1337 - acc: 0.9678\n",
      "Epoch 7/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.1121 - acc: 0.9717\n",
      "Epoch 8/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.1102 - acc: 0.9707\n",
      "Epoch 9/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0922 - acc: 0.9750\n",
      "Epoch 10/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0794 - acc: 0.9777\n",
      "Epoch 11/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0799 - acc: 0.9779\n",
      "Epoch 12/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0733 - acc: 0.9789\n",
      "Epoch 13/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0664 - acc: 0.9822\n",
      "Epoch 14/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0629 - acc: 0.9808\n",
      "Epoch 15/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0577 - acc: 0.9845: 0s - loss: 0.0570 - acc: 0.984\n",
      "Epoch 16/100\n",
      "9200/9200 [==============================] - 1s 66us/step - loss: 0.0523 - acc: 0.9845\n",
      "Epoch 17/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0535 - acc: 0.9845\n",
      "Epoch 18/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0582 - acc: 0.9817\n",
      "Epoch 19/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0470 - acc: 0.9861\n",
      "Epoch 20/100\n",
      "9200/9200 [==============================] - 1s 67us/step - loss: 0.0389 - acc: 0.9898\n",
      "Epoch 21/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0495 - acc: 0.9863\n",
      "Epoch 22/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0369 - acc: 0.9890\n",
      "Epoch 23/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0418 - acc: 0.9870\n",
      "Epoch 24/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0367 - acc: 0.9903\n",
      "Epoch 25/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0426 - acc: 0.9898\n",
      "Epoch 26/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0398 - acc: 0.9891\n",
      "Epoch 27/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0391 - acc: 0.9883\n",
      "Epoch 28/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0390 - acc: 0.9886\n",
      "Epoch 29/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0327 - acc: 0.9896\n",
      "Epoch 30/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0413 - acc: 0.9892\n",
      "Epoch 31/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0381 - acc: 0.9889\n",
      "Epoch 32/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0285 - acc: 0.9923\n",
      "Epoch 33/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0466 - acc: 0.9876\n",
      "Epoch 34/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0330 - acc: 0.9898\n",
      "Epoch 35/100\n",
      "9200/9200 [==============================] - 1s 67us/step - loss: 0.0335 - acc: 0.9910\n",
      "Epoch 36/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0284 - acc: 0.9925\n",
      "Epoch 37/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0219 - acc: 0.9937\n",
      "Epoch 38/100\n",
      "9200/9200 [==============================] - 1s 71us/step - loss: 0.0197 - acc: 0.9934\n",
      "Epoch 39/100\n",
      "9200/9200 [==============================] - 1s 70us/step - loss: 0.0378 - acc: 0.9888\n",
      "Epoch 40/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0338 - acc: 0.9916\n",
      "Epoch 41/100\n",
      "9200/9200 [==============================] - 1s 71us/step - loss: 0.0181 - acc: 0.9942\n",
      "Epoch 42/100\n",
      "9200/9200 [==============================] - 1s 70us/step - loss: 0.0191 - acc: 0.9954\n",
      "Epoch 43/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0336 - acc: 0.9895\n",
      "Epoch 44/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0268 - acc: 0.9918\n",
      "Epoch 45/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0297 - acc: 0.9916\n",
      "Epoch 46/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0245 - acc: 0.9924\n",
      "Epoch 47/100\n",
      "9200/9200 [==============================] - 1s 66us/step - loss: 0.0128 - acc: 0.9971\n",
      "Epoch 48/100\n",
      "9200/9200 [==============================] - 1s 67us/step - loss: 0.0150 - acc: 0.9964\n",
      "Epoch 49/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0303 - acc: 0.9901\n",
      "Epoch 50/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0285 - acc: 0.9918\n",
      "Epoch 51/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0306 - acc: 0.9918\n",
      "Epoch 52/100\n",
      "9200/9200 [==============================] - 1s 67us/step - loss: 0.0307 - acc: 0.9920\n",
      "Epoch 53/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0169 - acc: 0.9953: 0s - loss: 0.0172 - acc: 0.\n",
      "Epoch 54/100\n",
      "9200/9200 [==============================] - 1s 70us/step - loss: 0.0166 - acc: 0.9961\n",
      "Epoch 55/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0371 - acc: 0.9897\n",
      "Epoch 56/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0196 - acc: 0.9951: 0s - loss: 0.0211 - acc: 0.\n",
      "Epoch 57/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0232 - acc: 0.9936\n",
      "Epoch 58/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0333 - acc: 0.9917\n",
      "Epoch 59/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0168 - acc: 0.9955: 0s - loss: 0.0169 - acc: \n",
      "Epoch 60/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0201 - acc: 0.9948\n",
      "Epoch 61/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0307 - acc: 0.9925\n",
      "Epoch 62/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0124 - acc: 0.9966\n",
      "Epoch 63/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0237 - acc: 0.9935\n",
      "Epoch 64/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0149 - acc: 0.9955\n",
      "Epoch 65/100\n",
      "9200/9200 [==============================] - 1s 67us/step - loss: 0.0107 - acc: 0.9965\n",
      "Epoch 66/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0216 - acc: 0.9941\n",
      "Epoch 67/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0227 - acc: 0.9926\n",
      "Epoch 68/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0146 - acc: 0.9961\n",
      "Epoch 69/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0159 - acc: 0.9952\n",
      "Epoch 70/100\n",
      "9200/9200 [==============================] - 1s 66us/step - loss: 0.0118 - acc: 0.9960\n",
      "Epoch 71/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0249 - acc: 0.9920\n",
      "Epoch 72/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0159 - acc: 0.9960\n",
      "Epoch 73/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0163 - acc: 0.9942\n",
      "Epoch 74/100\n",
      "9200/9200 [==============================] - 1s 70us/step - loss: 0.0162 - acc: 0.9952\n",
      "Epoch 75/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0142 - acc: 0.9959\n",
      "Epoch 76/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0516 - acc: 0.9899: 0s - loss: 0.0608 - acc: 0.9\n",
      "Epoch 77/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0215 - acc: 0.9941: 0s - loss: 0.0199 - acc\n",
      "Epoch 78/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0145 - acc: 0.9963\n",
      "Epoch 79/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0087 - acc: 0.9978\n",
      "Epoch 80/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0214 - acc: 0.9937\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0255 - acc: 0.9936\n",
      "Epoch 82/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0311 - acc: 0.9928\n",
      "Epoch 83/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0164 - acc: 0.9953\n",
      "Epoch 84/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0156 - acc: 0.9961\n",
      "Epoch 85/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0233 - acc: 0.9935: 0s - loss: 0.0286 - acc: \n",
      "Epoch 86/100\n",
      "9200/9200 [==============================] - 1s 70us/step - loss: 0.0108 - acc: 0.9967\n",
      "Epoch 87/100\n",
      "9200/9200 [==============================] - 1s 65us/step - loss: 0.0189 - acc: 0.9948\n",
      "Epoch 88/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0197 - acc: 0.9934\n",
      "Epoch 89/100\n",
      "9200/9200 [==============================] - 1s 70us/step - loss: 0.0120 - acc: 0.9965\n",
      "Epoch 90/100\n",
      "9200/9200 [==============================] - 1s 71us/step - loss: 0.0081 - acc: 0.9978\n",
      "Epoch 91/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0059 - acc: 0.9984\n",
      "Epoch 92/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0118 - acc: 0.9970\n",
      "Epoch 93/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0392 - acc: 0.9898\n",
      "Epoch 94/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0200 - acc: 0.9946\n",
      "Epoch 95/100\n",
      "9200/9200 [==============================] - 1s 66us/step - loss: 0.0083 - acc: 0.9983\n",
      "Epoch 96/100\n",
      "9200/9200 [==============================] - 1s 67us/step - loss: 0.0116 - acc: 0.9976\n",
      "Epoch 97/100\n",
      "9200/9200 [==============================] - 1s 68us/step - loss: 0.0288 - acc: 0.9948: 0s - loss: 0.0251 - acc: 0.996 - ETA: 0s - loss: 0.0288 - acc: 0.9\n",
      "Epoch 98/100\n",
      "9200/9200 [==============================] - 1s 67us/step - loss: 0.0117 - acc: 0.9972\n",
      "Epoch 99/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0126 - acc: 0.9961: 0s - loss: 0.0129 - acc: 0.9\n",
      "Epoch 100/100\n",
      "9200/9200 [==============================] - 1s 69us/step - loss: 0.0080 - acc: 0.9974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1226e5b00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann1 = Sequential()\n",
    "ann1.add(Dense(output_dim = 80, init = 'uniform', activation = 'relu', input_dim = 178))\n",
    "ann1.add(Dense(output_dim = 80, init = 'uniform', activation = 'relu'))\n",
    "ann1.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "ann1.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "ann1.fit(X_train, Y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy:  95.86956521739131\n"
     ]
    }
   ],
   "source": [
    "Y_pred1 = ann1.predict(X_test)\n",
    "Y_pred1[Y_pred1 > 0.5] = 1\n",
    "Y_pred1[Y_pred1 <= 0.5] = 0\n",
    "acc_ann1 = accuracy_score(Y_test, Y_pred1) * 100\n",
    "print('testing accuracy: ', acc_ann1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=178, units=80, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=80, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9200/9200 [==============================] - 1s 80us/step - loss: 0.2019 - acc: 0.7983\n",
      "Epoch 2/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 3/100\n",
      "9200/9200 [==============================] - 1s 61us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 4/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 5/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 6/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 7/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 8/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 9/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 10/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 11/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 12/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 13/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 14/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 15/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 16/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 17/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 18/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 19/100\n",
      "9200/9200 [==============================] - 1s 65us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 20/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 21/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 22/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 23/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 24/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 25/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 26/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 27/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 28/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 29/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 30/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 31/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 32/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 33/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 34/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 35/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 36/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 37/100\n",
      "9200/9200 [==============================] - 1s 61us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 38/100\n",
      "9200/9200 [==============================] - 1s 62us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 39/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 40/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 41/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 42/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 43/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 44/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 45/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 46/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 47/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 48/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 49/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 50/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 51/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 52/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 53/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 54/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 55/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 56/100\n",
      "9200/9200 [==============================] - 1s 61us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 57/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 58/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.2017 - acc: 0.7983: 0s - loss: 0.2030 - acc: 0.7\n",
      "Epoch 59/100\n",
      "9200/9200 [==============================] - 1s 61us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 60/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 61/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 62/100\n",
      "9200/9200 [==============================] - 1s 61us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 63/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 64/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 65/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 66/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 67/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 68/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 69/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 70/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 71/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 72/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 73/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 74/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 75/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 76/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 77/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 78/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 79/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 80/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 81/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 83/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 84/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 85/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 86/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 87/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 88/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 89/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 90/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 91/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 92/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 93/100\n",
      "9200/9200 [==============================] - 1s 61us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 94/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 95/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 96/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 97/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 98/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 99/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 100/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2017 - acc: 0.7983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3cda42b0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann2 = Sequential()\n",
    "ann2.add(Dense(output_dim = 80, init = 'uniform', activation = 'relu', input_dim = 178))\n",
    "ann2.add(Dense(output_dim = 80, init = 'uniform', activation = 'relu'))\n",
    "ann2.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "ann2.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "ann2.fit(X_train, Y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy:  80.69565217391305\n"
     ]
    }
   ],
   "source": [
    "Y_pred2 = ann2.predict(X_test)\n",
    "Y_pred2[Y_pred2 > 0.5] = 1\n",
    "Y_pred2[Y_pred2 <= 0.5] = 0\n",
    "acc_ann2 = accuracy_score(Y_test, Y_pred2) * 100\n",
    "print('testing accuracy: ', acc_ann2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=178, units=80, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=80, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9200/9200 [==============================] - 1s 67us/step - loss: 0.2032 - acc: 0.7972\n",
      "Epoch 2/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2019 - acc: 0.7983\n",
      "Epoch 3/100\n",
      "9200/9200 [==============================] - 0s 50us/step - loss: 0.2018 - acc: 0.7983\n",
      "Epoch 4/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2018 - acc: 0.7983\n",
      "Epoch 5/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2018 - acc: 0.7983\n",
      "Epoch 6/100\n",
      "9200/9200 [==============================] - 0s 50us/step - loss: 0.2018 - acc: 0.7983\n",
      "Epoch 7/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2018 - acc: 0.7983\n",
      "Epoch 8/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2018 - acc: 0.7983\n",
      "Epoch 9/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2018 - acc: 0.7983\n",
      "Epoch 10/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2018 - acc: 0.7983\n",
      "Epoch 11/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2018 - acc: 0.7983\n",
      "Epoch 12/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2018 - acc: 0.7983\n",
      "Epoch 13/100\n",
      "9200/9200 [==============================] - 0s 50us/step - loss: 0.2018 - acc: 0.7983\n",
      "Epoch 14/100\n",
      "9200/9200 [==============================] - 0s 51us/step - loss: 0.2018 - acc: 0.7983\n",
      "Epoch 15/100\n",
      "9200/9200 [==============================] - 0s 50us/step - loss: 0.2018 - acc: 0.7983\n",
      "Epoch 16/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 17/100\n",
      "9200/9200 [==============================] - 0s 50us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 18/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 19/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 20/100\n",
      "9200/9200 [==============================] - 0s 50us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 21/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 22/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 23/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 24/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 25/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 26/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 27/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 28/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 29/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 30/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 31/100\n",
      "9200/9200 [==============================] - 0s 51us/step - loss: 0.2017 - acc: 0.7983: 0s - loss: 0.1991 - acc: 0.8\n",
      "Epoch 32/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 33/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 34/100\n",
      "9200/9200 [==============================] - 0s 50us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 35/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 36/100\n",
      "9200/9200 [==============================] - 0s 51us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 37/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 38/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 39/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 40/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 41/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 42/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 43/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 44/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 45/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 46/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 47/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 48/100\n",
      "9200/9200 [==============================] - 0s 50us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 49/100\n",
      "9200/9200 [==============================] - 0s 52us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 50/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 51/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 52/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 53/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 54/100\n",
      "9200/9200 [==============================] - 0s 48us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 55/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 56/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 57/100\n",
      "9200/9200 [==============================] - 0s 53us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 58/100\n",
      "9200/9200 [==============================] - 0s 50us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 59/100\n",
      "9200/9200 [==============================] - 0s 52us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 60/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 61/100\n",
      "9200/9200 [==============================] - 0s 51us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 62/100\n",
      "9200/9200 [==============================] - 0s 50us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 63/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 64/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 65/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 66/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 67/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 68/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 69/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 70/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 71/100\n",
      "9200/9200 [==============================] - 0s 50us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 72/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 73/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 74/100\n",
      "9200/9200 [==============================] - 0s 50us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 75/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 76/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 77/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 78/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 79/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 80/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 81/100\n",
      "9200/9200 [==============================] - 0s 52us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 83/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 84/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 85/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 86/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 87/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 88/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 89/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 90/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 91/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 92/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 93/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 94/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 95/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 96/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 97/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 98/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 99/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n",
      "Epoch 100/100\n",
      "9200/9200 [==============================] - 0s 49us/step - loss: 0.2017 - acc: 0.7983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4037e940>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann3 = Sequential()\n",
    "ann3.add(Dense(output_dim = 80, init = 'uniform', activation = 'relu', input_dim = 178))\n",
    "ann3.add(Dense(output_dim = 80, init = 'uniform', activation = 'relu'))\n",
    "ann3.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "ann3.compile(optimizer = 'SGD', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "ann3.fit(X_train, Y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy:  80.69565217391305\n"
     ]
    }
   ],
   "source": [
    "Y_pred3 = ann3.predict(X_test)\n",
    "Y_pred3[Y_pred3 > 0.5] = 1\n",
    "Y_pred3[Y_pred3 <= 0.5] = 0\n",
    "acc_ann3 = accuracy_score(Y_test, Y_pred3) * 100\n",
    "print('testing accuracy: ', acc_ann3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=178, units=80, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=80, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/Applications/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9200/9200 [==============================] - 1s 80us/step - loss: 0.4222 - acc: 0.8726\n",
      "Epoch 2/100\n",
      "9200/9200 [==============================] - 1s 61us/step - loss: 0.2244 - acc: 0.9505\n",
      "Epoch 3/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.1852 - acc: 0.9509\n",
      "Epoch 4/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.1665 - acc: 0.9527\n",
      "Epoch 5/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.1491 - acc: 0.9561\n",
      "Epoch 6/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.1466 - acc: 0.9579: 0s - loss: 0.1405 - acc: 0\n",
      "Epoch 7/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.1768 - acc: 0.9482\n",
      "Epoch 8/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.1975 - acc: 0.9407\n",
      "Epoch 9/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.2355 - acc: 0.9301\n",
      "Epoch 10/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4394 - acc: 0.8966\n",
      "Epoch 11/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.5769 - acc: 0.8691\n",
      "Epoch 12/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.8877 - acc: 0.8145\n",
      "Epoch 13/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.5283 - acc: 0.8209\n",
      "Epoch 14/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.5042 - acc: 0.8147\n",
      "Epoch 15/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4939 - acc: 0.8168\n",
      "Epoch 16/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.4732 - acc: 0.8183\n",
      "Epoch 17/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4749 - acc: 0.8189\n",
      "Epoch 18/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4772 - acc: 0.8218\n",
      "Epoch 19/100\n",
      "9200/9200 [==============================] - 1s 63us/step - loss: 0.5629 - acc: 0.8227\n",
      "Epoch 20/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.6483 - acc: 0.8017\n",
      "Epoch 21/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4963 - acc: 0.8074\n",
      "Epoch 22/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4791 - acc: 0.8162\n",
      "Epoch 23/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.5185 - acc: 0.8176\n",
      "Epoch 24/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4815 - acc: 0.8179\n",
      "Epoch 25/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 1.8194 - acc: 0.7533\n",
      "Epoch 26/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.5237 - acc: 0.8121\n",
      "Epoch 27/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4965 - acc: 0.8100\n",
      "Epoch 28/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4913 - acc: 0.8066\n",
      "Epoch 29/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4931 - acc: 0.8053\n",
      "Epoch 30/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4885 - acc: 0.8075\n",
      "Epoch 31/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4934 - acc: 0.8064\n",
      "Epoch 32/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4901 - acc: 0.8065\n",
      "Epoch 33/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 34/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 35/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4894 - acc: 0.8065: 0s - loss: 0.5081 - acc:\n",
      "Epoch 36/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 37/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 38/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065: 0s - loss: 0.4936 - acc: 0.\n",
      "Epoch 39/100\n",
      "9200/9200 [==============================] - 1s 61us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 40/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 41/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 42/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 43/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 44/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 45/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 46/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 47/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 48/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 49/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 50/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 51/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 52/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 53/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 54/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.4895 - acc: 0.8065: 0s - loss: 0.5063 - acc:\n",
      "Epoch 55/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 56/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 57/100\n",
      "9200/9200 [==============================] - 1s 58us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 58/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 59/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 60/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 61/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 62/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 63/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065: 0s - loss: 0.4917 - acc: 0.805\n",
      "Epoch 64/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 65/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 66/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 67/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 68/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065: 0s - loss: 0.4956 - acc: \n",
      "Epoch 69/100\n",
      "9200/9200 [==============================] - 1s 57us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 70/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 71/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 72/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 73/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 74/100\n",
      "9200/9200 [==============================] - 1s 63us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 75/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 76/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 77/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 78/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 79/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 80/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 82/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 83/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 84/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 85/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 86/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 87/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 88/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 89/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 90/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 91/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 92/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.4894 - acc: 0.8065\n",
      "Epoch 93/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 94/100\n",
      "9200/9200 [==============================] - 1s 60us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 95/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 96/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 97/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 98/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 99/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n",
      "Epoch 100/100\n",
      "9200/9200 [==============================] - 1s 59us/step - loss: 0.4895 - acc: 0.8065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4061bf28>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann4 = Sequential()\n",
    "ann4.add(Dense(output_dim = 80, init = 'uniform', activation = 'relu', input_dim = 178))\n",
    "ann4.add(Dense(output_dim = 80, init = 'uniform', activation = 'relu'))\n",
    "ann4.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "ann4.compile(optimizer = 'SGD', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "ann4.fit(X_train, Y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy:  81.52173913043478\n"
     ]
    }
   ],
   "source": [
    "Y_pred4 = ann4.predict(X_test)\n",
    "Y_pred4[Y_pred4 > 0.5] = 1\n",
    "Y_pred4[Y_pred4 <= 0.5] = 0\n",
    "acc_ann4 = accuracy_score(Y_test, Y_pred4) * 100\n",
    "print('testing accuracy: ', acc_ann4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_models = pd.DataFrame({\n",
    "    'Model': ['SVM', 'Linear SVM','KNN', 'Decision Tree', 'LDA', 'Random Forest', 'ANN'],\n",
    "    \n",
    "    'Score': [acc_svm, acc_linear_svm, acc_knn, acc_dt, acc_lda, acc_rf, acc_ann1]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>97.652174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>97.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ANN</td>\n",
       "      <td>95.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>95.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>94.565217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>84.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LDA</td>\n",
       "      <td>82.565217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model      Score\n",
       "0            SVM  97.652174\n",
       "5  Random Forest  97.173913\n",
       "6            ANN  95.869565\n",
       "2            KNN  95.086957\n",
       "3  Decision Tree  94.565217\n",
       "1     Linear SVM  84.043478\n",
       "4            LDA  82.565217"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
